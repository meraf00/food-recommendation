{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import os\n","import re\n","\n","from sklearn.preprocessing import MultiLabelBinarizer\n","from sklearn.preprocessing import OneHotEncoder"]},{"cell_type":"code","execution_count":11,"metadata":{"trusted":true},"outputs":[],"source":["df_anime = pd.read_csv(\"../input/anime-recommendations-database/anime.csv\")\n","df_rating = pd.read_csv(\"../input/anime-recommendations-database/rating.csv\")"]},{"cell_type":"code","execution_count":12,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>anime_id</th>\n","      <th>name</th>\n","      <th>genre</th>\n","      <th>type</th>\n","      <th>episodes</th>\n","      <th>rating</th>\n","      <th>members</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>32281</td>\n","      <td>Kimi no Na wa.</td>\n","      <td>Drama, Romance, School, Supernatural</td>\n","      <td>Movie</td>\n","      <td>1</td>\n","      <td>9.37</td>\n","      <td>200630</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5114</td>\n","      <td>Fullmetal Alchemist: Brotherhood</td>\n","      <td>Action, Adventure, Drama, Fantasy, Magic, Mili...</td>\n","      <td>TV</td>\n","      <td>64</td>\n","      <td>9.26</td>\n","      <td>793665</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>28977</td>\n","      <td>Gintama°</td>\n","      <td>Action, Comedy, Historical, Parody, Samurai, S...</td>\n","      <td>TV</td>\n","      <td>51</td>\n","      <td>9.25</td>\n","      <td>114262</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9253</td>\n","      <td>Steins;Gate</td>\n","      <td>Sci-Fi, Thriller</td>\n","      <td>TV</td>\n","      <td>24</td>\n","      <td>9.17</td>\n","      <td>673572</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>9969</td>\n","      <td>Gintama&amp;#039;</td>\n","      <td>Action, Comedy, Historical, Parody, Samurai, S...</td>\n","      <td>TV</td>\n","      <td>51</td>\n","      <td>9.16</td>\n","      <td>151266</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   anime_id                              name  \\\n","0     32281                    Kimi no Na wa.   \n","1      5114  Fullmetal Alchemist: Brotherhood   \n","2     28977                          Gintama°   \n","3      9253                       Steins;Gate   \n","4      9969                     Gintama&#039;   \n","\n","                                               genre   type episodes  rating  \\\n","0               Drama, Romance, School, Supernatural  Movie        1    9.37   \n","1  Action, Adventure, Drama, Fantasy, Magic, Mili...     TV       64    9.26   \n","2  Action, Comedy, Historical, Parody, Samurai, S...     TV       51    9.25   \n","3                                   Sci-Fi, Thriller     TV       24    9.17   \n","4  Action, Comedy, Historical, Parody, Samurai, S...     TV       51    9.16   \n","\n","   members  \n","0   200630  \n","1   793665  \n","2   114262  \n","3   673572  \n","4   151266  "]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["df_anime.head()"]},{"cell_type":"code","execution_count":13,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user_id</th>\n","      <th>anime_id</th>\n","      <th>rating</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>20</td>\n","      <td>-1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>24</td>\n","      <td>-1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>79</td>\n","      <td>-1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>226</td>\n","      <td>-1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>241</td>\n","      <td>-1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   user_id  anime_id  rating\n","0        1        20      -1\n","1        1        24      -1\n","2        1        79      -1\n","3        1       226      -1\n","4        1       241      -1"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["df_rating.head()"]},{"cell_type":"code","execution_count":14,"metadata":{"trusted":true},"outputs":[],"source":["def get_anime_feature_map(df_anime):\n","    ## cleaning names\n","    # df_anime['name'] = df_anime['name'].apply(lambda x: re.sub(r'[^A-Za-z0-9 ]+', '', re.sub(r'&#(\\d)+;', '', x)))\n","    # df_anime = df_anime[df_anime['name'] != '']\n","    \n","    # ## Imputing episodes based on type of anime(mean value)\n","    tmp = df_anime[df_anime.episodes != 'Unknown'][['type', 'episodes']]\n","    tmp['episodes'] = tmp['episodes'].astype(int)\n","    tmp = tmp.groupby('type').mean().to_dict()['episodes']\n","    df_anime['episodes'] = df_anime.apply(lambda x: tmp.get(x['type'], 1) if (x['episodes'] == 'Unknown') else x['episodes'], axis=1)\n","    df_anime['episodes'] = df_anime['episodes'].astype(int)\n","    \n","    ## Imputing rating with the mean rating\n","    df_anime['rating'] = df_anime['rating'].fillna(df_anime['rating'].mean())\n","    \n","    #Imputing genre with extra '' class\n","    df_anime['genre'] = df_anime['genre'].apply(lambda x: [g.strip() for g in (x.split(',') if (type(x) == str) else [''])])\n","    mat = df_anime.to_numpy()\n","    genres = mat[:,2]\n","    \n","    mlb = MultiLabelBinarizer()\n","    mlb.fit(genres)\n","    \n","    ## Imputing type column with extra '' class\n","    df_anime['type'] = df_anime['type'].fillna('')\n","    \n","    ohe = OneHotEncoder(sparse=False)\n","    ohe.fit(np.array(list(set(df_anime['type']))).reshape(-1, 1))\n","    \n","    df_anime['genre'] = df_anime['genre'].apply(lambda x: mlb.transform([x])[0])\n","    df_anime['type'] = df_anime['type'].apply(lambda x: ohe.transform([[x]])[0])\n","    \n","    ## normalize ratings and members\n","    df_anime['rating'] = (df_anime['rating'] - df_anime['rating'].min())/(df_anime['rating'].max()-df_anime['rating'].min())\n","    df_anime['members'] = (df_anime['members'] - df_anime['members'].min())/(df_anime['members'].max()-df_anime['members'].min())\n","    \n","    ## generating feature_map\n","    anime_feature_map = {}\n","    for idx, row in tqdm(df_anime.iterrows()):\n","        anime_feature_map[row[\"anime_id\"]] = list(row[\"genre\"]) + list(row[\"type\"]) + [row[\"rating\"], row[\"members\"]]\n","        \n","    return anime_feature_map, mlb, ohe"]},{"cell_type":"code","execution_count":15,"metadata":{"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["12294it [00:01, 8303.78it/s]\n"]}],"source":["anime_feature_map, mlb, ohe = get_anime_feature_map(df_anime)"]},{"cell_type":"code","execution_count":16,"metadata":{"trusted":true},"outputs":[],"source":["# df_rating.head()\n","df_rating['anime_features'] = df_rating['anime_id'].apply(lambda x: anime_feature_map.get(x))\n","df_rating = df_rating[~df_rating.anime_features.isna()]\n","df_rating = df_rating[df_rating['rating'] != -1]"]},{"cell_type":"code","execution_count":17,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user_id</th>\n","      <th>anime_id</th>\n","      <th>rating</th>\n","      <th>anime_features</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>47</th>\n","      <td>1</td>\n","      <td>8074</td>\n","      <td>10</td>\n","      <td>[0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, ...</td>\n","    </tr>\n","    <tr>\n","      <th>81</th>\n","      <td>1</td>\n","      <td>11617</td>\n","      <td>10</td>\n","      <td>[0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>83</th>\n","      <td>1</td>\n","      <td>11757</td>\n","      <td>10</td>\n","      <td>[0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>101</th>\n","      <td>1</td>\n","      <td>15451</td>\n","      <td>10</td>\n","      <td>[0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>153</th>\n","      <td>2</td>\n","      <td>11771</td>\n","      <td>10</td>\n","      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     user_id  anime_id  rating  \\\n","47         1      8074      10   \n","81         1     11617      10   \n","83         1     11757      10   \n","101        1     15451      10   \n","153        2     11771      10   \n","\n","                                        anime_features  \n","47   [0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, ...  \n","81   [0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, ...  \n","83   [0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, ...  \n","101  [0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, ...  \n","153  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["df_rating.head()"]},{"cell_type":"code","execution_count":18,"metadata":{"trusted":true},"outputs":[],"source":["user_count = df_rating.groupby('user_id').count()['rating']\n","df_rating = df_rating[df_rating['user_id'].apply(lambda x: 5 <= user_count[x] <= 100)]"]},{"cell_type":"code","execution_count":19,"metadata":{"trusted":true},"outputs":[],"source":["user_idx_map = {u: e for e, u in enumerate(df_rating.user_id.unique())}\n","anime_idx_map = {i: e for e, i in enumerate(df_rating.anime_id.unique())}"]},{"cell_type":"code","execution_count":20,"metadata":{"trusted":true},"outputs":[],"source":["df_rating[\"user_idx\"] = df_rating[\"user_id\"].apply(lambda x: user_idx_map[x])\n","df_rating[\"anime_idx\"] = df_rating[\"anime_id\"].apply(lambda x: anime_idx_map[x])"]},{"cell_type":"code","execution_count":21,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["41171\n","7185\n"]}],"source":["print(df_rating[\"user_idx\"].max())\n","print(df_rating[\"anime_idx\"].max())"]},{"cell_type":"code","execution_count":22,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user_id</th>\n","      <th>anime_id</th>\n","      <th>rating</th>\n","      <th>anime_features</th>\n","      <th>user_idx</th>\n","      <th>anime_idx</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>156</th>\n","      <td>3</td>\n","      <td>20</td>\n","      <td>8</td>\n","      <td>[0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>157</th>\n","      <td>3</td>\n","      <td>154</td>\n","      <td>6</td>\n","      <td>[0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>158</th>\n","      <td>3</td>\n","      <td>170</td>\n","      <td>9</td>\n","      <td>[0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>159</th>\n","      <td>3</td>\n","      <td>199</td>\n","      <td>10</td>\n","      <td>[0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>0</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>160</th>\n","      <td>3</td>\n","      <td>225</td>\n","      <td>9</td>\n","      <td>[0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...</td>\n","      <td>0</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     user_id  anime_id  rating  \\\n","156        3        20       8   \n","157        3       154       6   \n","158        3       170       9   \n","159        3       199      10   \n","160        3       225       9   \n","\n","                                        anime_features  user_idx  anime_idx  \n","156  [0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...         0          0  \n","157  [0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...         0          1  \n","158  [0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...         0          2  \n","159  [0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...         0          3  \n","160  [0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...         0          4  "]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["df_rating.head()"]},{"cell_type":"code","execution_count":23,"metadata":{"trusted":true},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","df_rating_train, df_rating_test = train_test_split(df_rating, test_size=0.1, stratify=df_rating.user_id, random_state=93)"]},{"cell_type":"code","execution_count":59,"metadata":{"trusted":true},"outputs":[],"source":["X_train = [df_rating_train['user_idx'].values, df_rating_train['anime_idx'].values, np.array([np.array(t) for t in df_rating_train['anime_features']])]\n","y_train = df_rating_train['rating'].values\n","\n","X_test = [df_rating_test['user_idx'].values, df_rating_test['anime_idx'].values, np.array([np.array(t) for t in df_rating_test['anime_features']])]\n","y_test = df_rating_test['rating'].values"]},{"cell_type":"code","execution_count":61,"metadata":{"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","tf.compat.v1.disable_v2_behavior()\n","import tensorflow.keras as keras\n","from tensorflow.keras.layers import Input, Embedding, Dot, Concatenate, Add, Flatten, Dense, Dropout, BatchNormalization\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam"]},{"cell_type":"code","execution_count":79,"metadata":{"trusted":true},"outputs":[],"source":["def create_model(n_users, user_embed_size_dot, user_embed_size_concat, n_items, item_embed_size, item_feature_len, regularization=1e-4):\n","     \n","    item_features = Input(shape=(item_feature_len, ), name=\"item_features\")\n","    user_inp = Input(shape=(1, ), dtype='int32', name=\"user_embed\")\n","    user_embed = Embedding(n_users, \n","                           user_embed_size_dot, \n","                           name='user_embed_mat',\n","                           embeddings_initializer=\"glorot_uniform\", \n","                           embeddings_regularizer=keras.regularizers.l2(regularization))(user_inp)\n","    user_embed_bias = Embedding(n_users, \n","                                1, \n","                                name='user_embed_bias_mat',\n","                                embeddings_initializer=\"glorot_uniform\")(user_inp)\n","    user_embed_c = Embedding(n_users, \n","                             user_embed_size_concat, \n","                             name='user_embed_c_mat',\n","                             embeddings_initializer=\"glorot_uniform\", \n","                             embeddings_regularizer=keras.regularizers.l2(regularization))(user_inp)\n","    \n","    item_inp = Input(shape=(1, ), dtype='int32', name=\"item_embed\")\n","    item_embed = Embedding(n_items, \n","                           item_embed_size, \n","                           name='item_embed_mat',\n","                           embeddings_initializer=\"glorot_uniform\", \n","                           embeddings_regularizer=keras.regularizers.l2(regularization))(item_inp)\n","    item_embed_bias = Embedding(n_items, \n","                                1, \n","                                name='item_embed_bias_mat',\n","                                embeddings_initializer=\"glorot_uniform\")(item_inp)\n","    \n","    user_item_dot = Dot(axes=2, name='user_item_dot')([user_embed, item_embed])\n","    \n","    user_item_dot = Add()([user_item_dot, user_embed_bias, item_embed_bias])\n","    user_item_dot = Flatten()(user_item_dot)\n","    user_embed_c = Flatten()(user_embed_c)\n","    \n","    user_item_concat = Concatenate(axis=1)([user_embed_c, item_features])\n","    \n","    hidden1 = Dense(8, activation=\"relu\")(user_item_concat)\n","    hidden1 = BatchNormalization()(hidden1)\n","    hidden1 = Dropout(0.2)(hidden1)\n","    \n","    dot_hidden1_concat = Concatenate(axis=1)([hidden1, user_item_dot])\n","    \n","    output = Dense(1, activation=\"relu\")(dot_hidden1_concat)\n","    \n","    model = Model([user_inp, item_inp, item_features], output)\n","    \n","    return model\n","    "]},{"cell_type":"code","execution_count":80,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model_7\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","user_embed (InputLayer)         [(None, 1)]          0                                            \n","__________________________________________________________________________________________________\n","user_embed_c_mat (Embedding)    (None, 1, 20)        823440      user_embed[0][0]                 \n","__________________________________________________________________________________________________\n","flatten_15 (Flatten)            (None, 20)           0           user_embed_c_mat[0][0]           \n","__________________________________________________________________________________________________\n","item_features (InputLayer)      [(None, 53)]         0                                            \n","__________________________________________________________________________________________________\n","item_embed (InputLayer)         [(None, 1)]          0                                            \n","__________________________________________________________________________________________________\n","concatenate_14 (Concatenate)    (None, 73)           0           flatten_15[0][0]                 \n","                                                                 item_features[0][0]              \n","__________________________________________________________________________________________________\n","user_embed_mat (Embedding)      (None, 1, 20)        823440      user_embed[0][0]                 \n","__________________________________________________________________________________________________\n","item_embed_mat (Embedding)      (None, 1, 20)        143720      item_embed[0][0]                 \n","__________________________________________________________________________________________________\n","dense_14 (Dense)                (None, 8)            592         concatenate_14[0][0]             \n","__________________________________________________________________________________________________\n","user_item_dot (Dot)             (None, 1, 1)         0           user_embed_mat[0][0]             \n","                                                                 item_embed_mat[0][0]             \n","__________________________________________________________________________________________________\n","user_embed_bias_mat (Embedding) (None, 1, 1)         41172       user_embed[0][0]                 \n","__________________________________________________________________________________________________\n","item_embed_bias_mat (Embedding) (None, 1, 1)         7186        item_embed[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_7 (BatchNor (None, 8)            32          dense_14[0][0]                   \n","__________________________________________________________________________________________________\n","add_7 (Add)                     (None, 1, 1)         0           user_item_dot[0][0]              \n","                                                                 user_embed_bias_mat[0][0]        \n","                                                                 item_embed_bias_mat[0][0]        \n","__________________________________________________________________________________________________\n","dropout_7 (Dropout)             (None, 8)            0           batch_normalization_7[0][0]      \n","__________________________________________________________________________________________________\n","flatten_14 (Flatten)            (None, 1)            0           add_7[0][0]                      \n","__________________________________________________________________________________________________\n","concatenate_15 (Concatenate)    (None, 9)            0           dropout_7[0][0]                  \n","                                                                 flatten_14[0][0]                 \n","__________________________________________________________________________________________________\n","dense_15 (Dense)                (None, 1)            10          concatenate_15[0][0]             \n","==================================================================================================\n","Total params: 1,839,592\n","Trainable params: 1,839,576\n","Non-trainable params: 16\n","__________________________________________________________________________________________________\n"]}],"source":["N_USERS = df_rating.user_idx.max() + 1\n","N_ITEMS = df_rating.anime_idx.max() + 1\n","USER_EMBEDDING_SIZE_DOT = 20\n","USER_EMBEDDING_SIZE_CONCAT = 20\n","ITEM_EMBEDDING_SIZE = 20\n","ITEM_FEATURE_LEN = 53\n","\n","model = create_model(N_USERS, USER_EMBEDDING_SIZE_DOT, USER_EMBEDDING_SIZE_CONCAT, N_ITEMS, ITEM_EMBEDDING_SIZE, ITEM_FEATURE_LEN)\n","model.summary()"]},{"cell_type":"code","execution_count":81,"metadata":{"trusted":true},"outputs":[],"source":["model.compile(Adam(1e-3), loss=\"mse\", metrics=[\"mae\"])"]},{"cell_type":"code","execution_count":82,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Train on 1272119 samples, validate on 141347 samples\n","Epoch 1/50\n","1272096/1272119 [============================>.] - ETA: 0s - loss: 2.6935 - mean_absolute_error: 1.1691"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n","  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 00001: val_loss improved from inf to 1.64769, saving model to best_model.h5\n","1272119/1272119 [==============================] - 387s 304us/sample - loss: 2.6935 - mean_absolute_error: 1.1691 - val_loss: 1.6477 - val_mean_absolute_error: 0.9618\n","Epoch 2/50\n","1272119/1272119 [==============================] - ETA: 0s - loss: 1.5719 - mean_absolute_error: 0.9400\n","Epoch 00002: val_loss improved from 1.64769 to 1.60568, saving model to best_model.h5\n","1272119/1272119 [==============================] - 368s 289us/sample - loss: 1.5719 - mean_absolute_error: 0.9400 - val_loss: 1.6057 - val_mean_absolute_error: 0.9495\n","Epoch 3/50\n","1272119/1272119 [==============================] - ETA: 0s - loss: 1.5287 - mean_absolute_error: 0.9272\n","Epoch 00003: val_loss improved from 1.60568 to 1.58443, saving model to best_model.h5\n","1272119/1272119 [==============================] - 359s 282us/sample - loss: 1.5287 - mean_absolute_error: 0.9272 - val_loss: 1.5844 - val_mean_absolute_error: 0.9472\n","Epoch 4/50\n","1272064/1272119 [============================>.] - ETA: 0s - loss: 1.5066 - mean_absolute_error: 0.9213\n","Epoch 00004: val_loss improved from 1.58443 to 1.57598, saving model to best_model.h5\n","1272119/1272119 [==============================] - 358s 282us/sample - loss: 1.5066 - mean_absolute_error: 0.9213 - val_loss: 1.5760 - val_mean_absolute_error: 0.9454\n","Epoch 5/50\n","1272096/1272119 [============================>.] - ETA: 0s - loss: 1.4922 - mean_absolute_error: 0.9174\n","Epoch 00005: val_loss improved from 1.57598 to 1.56905, saving model to best_model.h5\n","1272119/1272119 [==============================] - 354s 278us/sample - loss: 1.4922 - mean_absolute_error: 0.9174 - val_loss: 1.5690 - val_mean_absolute_error: 0.9442\n","Epoch 6/50\n","1272096/1272119 [============================>.] - ETA: 0s - loss: 1.4815 - mean_absolute_error: 0.9142\n","Epoch 00006: val_loss improved from 1.56905 to 1.56626, saving model to best_model.h5\n","1272119/1272119 [==============================] - 352s 277us/sample - loss: 1.4816 - mean_absolute_error: 0.9142 - val_loss: 1.5663 - val_mean_absolute_error: 0.9429\n","Epoch 7/50\n","1271968/1272119 [============================>.] - ETA: 0s - loss: 1.4740 - mean_absolute_error: 0.9119\n","Epoch 00007: val_loss improved from 1.56626 to 1.56256, saving model to best_model.h5\n","1272119/1272119 [==============================] - 351s 276us/sample - loss: 1.4740 - mean_absolute_error: 0.9119 - val_loss: 1.5626 - val_mean_absolute_error: 0.9442\n","Epoch 8/50\n","1272032/1272119 [============================>.] - ETA: 0s - loss: 1.4681 - mean_absolute_error: 0.9102\n","Epoch 00008: val_loss improved from 1.56256 to 1.56150, saving model to best_model.h5\n","1272119/1272119 [==============================] - 352s 276us/sample - loss: 1.4680 - mean_absolute_error: 0.9102 - val_loss: 1.5615 - val_mean_absolute_error: 0.9434\n","Epoch 9/50\n","1272000/1272119 [============================>.] - ETA: 0s - loss: 1.4629 - mean_absolute_error: 0.9086\n","Epoch 00009: val_loss improved from 1.56150 to 1.56019, saving model to best_model.h5\n","1272119/1272119 [==============================] - 353s 277us/sample - loss: 1.4629 - mean_absolute_error: 0.9086 - val_loss: 1.5602 - val_mean_absolute_error: 0.9447\n","Epoch 10/50\n","1271968/1272119 [============================>.] - ETA: 0s - loss: 1.4589 - mean_absolute_error: 0.9074\n","Epoch 00010: val_loss improved from 1.56019 to 1.55877, saving model to best_model.h5\n","1272119/1272119 [==============================] - 350s 275us/sample - loss: 1.4588 - mean_absolute_error: 0.9074 - val_loss: 1.5588 - val_mean_absolute_error: 0.9434\n","Epoch 11/50\n","1272000/1272119 [============================>.] - ETA: 0s - loss: 1.4555 - mean_absolute_error: 0.9062\n","Epoch 00011: val_loss improved from 1.55877 to 1.55805, saving model to best_model.h5\n","1272119/1272119 [==============================] - 349s 274us/sample - loss: 1.4554 - mean_absolute_error: 0.9062 - val_loss: 1.5581 - val_mean_absolute_error: 0.9432\n","Epoch 12/50\n","1272096/1272119 [============================>.] - ETA: 0s - loss: 1.4526 - mean_absolute_error: 0.9053\n","Epoch 00012: val_loss improved from 1.55805 to 1.55772, saving model to best_model.h5\n","1272119/1272119 [==============================] - 349s 274us/sample - loss: 1.4526 - mean_absolute_error: 0.9053 - val_loss: 1.5577 - val_mean_absolute_error: 0.9432\n","Epoch 13/50\n","1272064/1272119 [============================>.] - ETA: 0s - loss: 1.4501 - mean_absolute_error: 0.9045\n","Epoch 00013: val_loss did not improve from 1.55772\n","1272119/1272119 [==============================] - 348s 273us/sample - loss: 1.4501 - mean_absolute_error: 0.9045 - val_loss: 1.5580 - val_mean_absolute_error: 0.9427\n","Epoch 14/50\n","1272064/1272119 [============================>.] - ETA: 0s - loss: 1.4479 - mean_absolute_error: 0.9038\n","Epoch 00014: val_loss improved from 1.55772 to 1.55743, saving model to best_model.h5\n","1272119/1272119 [==============================] - 352s 276us/sample - loss: 1.4479 - mean_absolute_error: 0.9038 - val_loss: 1.5574 - val_mean_absolute_error: 0.9430\n","Epoch 15/50\n","1272119/1272119 [==============================] - ETA: 0s - loss: 1.4462 - mean_absolute_error: 0.9032\n","Epoch 00015: val_loss improved from 1.55743 to 1.55683, saving model to best_model.h5\n","1272119/1272119 [==============================] - 350s 275us/sample - loss: 1.4462 - mean_absolute_error: 0.9032 - val_loss: 1.5568 - val_mean_absolute_error: 0.9426\n","Epoch 16/50\n","1272119/1272119 [==============================] - ETA: 0s - loss: 1.4446 - mean_absolute_error: 0.9027\n","Epoch 00016: val_loss improved from 1.55683 to 1.55676, saving model to best_model.h5\n","1272119/1272119 [==============================] - 351s 276us/sample - loss: 1.4446 - mean_absolute_error: 0.9027 - val_loss: 1.5568 - val_mean_absolute_error: 0.9434\n","Epoch 17/50\n","1272032/1272119 [============================>.] - ETA: 0s - loss: 1.4433 - mean_absolute_error: 0.9022\n","Epoch 00017: val_loss improved from 1.55676 to 1.55657, saving model to best_model.h5\n","1272119/1272119 [==============================] - 351s 276us/sample - loss: 1.4433 - mean_absolute_error: 0.9022 - val_loss: 1.5566 - val_mean_absolute_error: 0.9438\n","Epoch 18/50\n","1272096/1272119 [============================>.] - ETA: 0s - loss: 1.4419 - mean_absolute_error: 0.9017\n","Epoch 00018: val_loss improved from 1.55657 to 1.55652, saving model to best_model.h5\n","1272119/1272119 [==============================] - 351s 276us/sample - loss: 1.4419 - mean_absolute_error: 0.9017 - val_loss: 1.5565 - val_mean_absolute_error: 0.9429\n","Epoch 19/50\n","1272096/1272119 [============================>.] - ETA: 0s - loss: 1.4410 - mean_absolute_error: 0.9014\n","Epoch 00019: val_loss improved from 1.55652 to 1.55623, saving model to best_model.h5\n","1272119/1272119 [==============================] - 352s 276us/sample - loss: 1.4410 - mean_absolute_error: 0.9014 - val_loss: 1.5562 - val_mean_absolute_error: 0.9431\n","Epoch 20/50\n","1272064/1272119 [============================>.] - ETA: 0s - loss: 1.4399 - mean_absolute_error: 0.9011\n","Epoch 00020: val_loss did not improve from 1.55623\n","1272119/1272119 [==============================] - 351s 276us/sample - loss: 1.4399 - mean_absolute_error: 0.9011 - val_loss: 1.5566 - val_mean_absolute_error: 0.9430\n","Epoch 21/50\n","1271968/1272119 [============================>.] - ETA: 0s - loss: 1.4392 - mean_absolute_error: 0.9008\n","Epoch 00021: val_loss did not improve from 1.55623\n","1272119/1272119 [==============================] - 349s 275us/sample - loss: 1.4392 - mean_absolute_error: 0.9008 - val_loss: 1.5564 - val_mean_absolute_error: 0.9436\n","Epoch 22/50\n","1272000/1272119 [============================>.] - ETA: 0s - loss: 1.4384 - mean_absolute_error: 0.9005\n","Epoch 00022: val_loss did not improve from 1.55623\n","1272119/1272119 [==============================] - 347s 273us/sample - loss: 1.4384 - mean_absolute_error: 0.9005 - val_loss: 1.5563 - val_mean_absolute_error: 0.9437\n","Epoch 23/50\n","1272000/1272119 [============================>.] - ETA: 0s - loss: 1.4378 - mean_absolute_error: 0.9003\n","Epoch 00023: val_loss did not improve from 1.55623\n","1272119/1272119 [==============================] - 346s 272us/sample - loss: 1.4378 - mean_absolute_error: 0.9003 - val_loss: 1.5566 - val_mean_absolute_error: 0.9431\n","Epoch 24/50\n","1272064/1272119 [============================>.] - ETA: 0s - loss: 1.4374 - mean_absolute_error: 0.9001\n","Epoch 00024: val_loss did not improve from 1.55623\n","1272119/1272119 [==============================] - 349s 275us/sample - loss: 1.4374 - mean_absolute_error: 0.9001 - val_loss: 1.5565 - val_mean_absolute_error: 0.9434\n","Epoch 00024: early stopping\n"]},{"data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f56844d0850>"]},"execution_count":82,"metadata":{},"output_type":"execute_result"}],"source":["# callbacks defined\n","\n","# learning rate schedule\n","def step_decay(epoch):\n","    initial_lrate = 0.001\n","    drop = 0.5\n","    epochs_drop = 5\n","    lrate = initial_lrate * (drop**((1 + epoch)/epochs_drop))\n","    return lrate\n","\n","lrate_scheduler = LearningRateScheduler(step_decay)\n","early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n","model_chkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n","\n","# model fitting\n","model.fit(X_train, y_train, batch_size=32, epochs=50, validation_split=0.1, callbacks=[early_stop, model_chkpoint, lrate_scheduler])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model.predict(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df_rating_test['prediction'] = [t[0] for t in model.predict(X_test)]"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df_rating_test.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["print(\"Test MAE: {}\".format(sum(abs(df_rating_test[\"rating\"] - df_rating_test[\"prediction\"]))/len(df_rating_test)))"]},{"cell_type":"markdown","metadata":{},"source":["### Upvote if you liked the approach."]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"}},"nbformat":4,"nbformat_minor":4}
